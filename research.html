<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Duarte Lab @ UCSD</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Favicons -->
    <link rel="apple-touch-icon" sizes="180x180" href="favicon_io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon_io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon_io/favicon-16x16.png">
    <link rel="manifest" href="favicon_io/site.webmanifest">

  <!-- Custom styles for this template -->
  <link href="css/modern-business.css" rel="stylesheet">
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110952733-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110952733-2');
</script>
</head>

<body>

  <!-- Navigation -->
  <nav class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark fixed-top">
    <div class="container">
      <a class="navbar-brand" href="#"><h4>Duarte Lab @ UCSD <font color="lightgray"><small>Particle Physics and Machine Learning</small></font></h4></a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="index.html">About</a>
          </li>
          <li class="nav-item active">
            <a class="nav-link" href="research.html">Research</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="people.html">People</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="teaching.html">Teaching</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="resources.html">Resources</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Page Content -->
  <div class="container">

    <!-- Page Heading/Breadcrumbs -->
    <h1 class="mt-4 mb-3">Research
    </h1>

    <ol class="breadcrumb">
      <li class="breadcrumb-item">
        <a href="index.html">About</a>
      </li>
      <li class="breadcrumb-item active">Research</li>
    </ol>

    <!-- Intro Content -->
    <div class="row">
<div class="col-lg-6">
<img class="img-fluid rounded mb-4" src="images/schematic.png" alt="" width="500">
</div>
<div class="col-lg-6">
<h2>Real-time artificial intelligence for accelerator control: A study at the Fermilab Booster</h2>
<p>We describe a method for precisely regulating the gradient magnet power supply at the Fermilab Booster accelerator complex using a neural network trained via reinforcement learning.
  We demonstrate preliminary results by training a surrogate machine-learning model on real accelerator data to emulate the Booster environment, and using this surrogate model in turn to train the neural network for its regulation task.
  We additionally show how the neural networks to be deployed for control purposes may be compiled to execute on field-programmable gate arrays. This capability is important for operational stability in complicated environments such as an accelerator facility.
</p>
<p>Paper: <a href="https://arxiv.org/abs/2011.07371">arXiv:2011.07371</a>
<br>Code: <a href="https://github.com/fermilab-accelerator-ai/control-for-accelerators-in-hep">https://github.com/fermilab-accelerator-ai/control-for-accelerators-in-hep</a>
</div>
</div>
    <div class="row">
<div class="col-lg-6">
<img class="img-fluid rounded mb-4" src="images/ml-suite-sever-structure.png" alt="" width="500">
</div>
<div class="col-lg-6">
<h2>FPGAs-as-a-service toolkit (FaaST)</h2>
<p>Computing needs for high energy physics are already intensive and are expected to increase drastically in the coming years.
In this context, heterogeneous computing, specifically as-a-service computing, has the potential for significant gains over traditional computing models.
Although previous studies and packages in the field of heterogeneous computing have focused on GPUs as accelerators, FPGAs are an extremely promising option as well.
A series of workflows are developed to establish the performance capabilities of FPGAs as a service.
Multiple different devices and a range of algorithms for use in high energy physics are studied.
For a small, dense network, the throughput can be improved by an order of magnitude with respect to GPUs as a service.
For large convolutional networks, the throughput is found to be comparable to GPUs as a service.
This work represents the first open-source FPGAs-as-a-service toolkit.
</p>
<p>Paper: <a href="https://arxiv.org/abs/2010.08556">arXiv:2010.08556</a>
<br>Code: <a href="https://github.com/hls-fpga-machine-learning/FaaST">https://github.com/hls-fpga-machine-learning/FaaST</a>
</div>
</div>
    <div class="row">
<div class="col-lg-6">
<img class="img-fluid rounded mb-4" src="images/garnet_event_display.png" alt="" width="500">
</div>
<div class="col-lg-6">
<h2>Distance-weighted graph neural networks on FPGAs for real-time particle reconstruction in high energy physics</h2>
<p>We use a graph neural network architecture developed for real-time particle reconstruction and identification in a next-generation calorimeter and simplify it to meet the computing constraints of Level-1 trigger systems, including weight quantization.
  We show how it can be executed with a latency of less than 1\(\mu\)s on an FPGA.
  Using the \(\texttt{hls4ml}\) library, we convert the compressed models into FPGA firmware.
  Performance of the synthesized models is presented both in terms of inference accuracy and resource usage.
</p>
<p>Paper: <a href="https://arxiv.org/abs/2008.03601">arXiv:2008.03601</a>
<br>Code: <a href="https://github.com/hls-fpga-machine-learning/hls4ml/pull/213">https://github.com/hls-fpga-machine-learning/hls4ml/pull/213</a>
</div>
</div>
        <div class="row">
    <div class="col-lg-6">
<img class="img-fluid rounded mb-4" src="images/GPUaaS.png" alt="" width="500">
</div>
<div class="col-lg-6">
<h2>GPU coprocessors as a service for deep learning inference in high energy physics</h2>
<p>We present a comprehensive exploration of the use of GPU-based hardware acceleration for deep learning inference within the data reconstruction workflow of high energy physics.
  We present several realistic examples and discuss a strategy for the seamless integration of coprocessors so that the CERN LHC can maintain, if not exceed, its current performance throughout its running.
</p>
<p>Paper: <a href="https://arxiv.org/abs/2007.10359">arXiv:2007.10359</a>
<br>Code: <a href="https://github.com/hls-fpga-machine-learning/SonicCMS">https://github.com/hls-fpga-machine-learning/SonicCMS</a>
</div>
</div>
    <div class="row">
<div class="col-lg-6">
<img class="img-fluid rounded mb-4" src="images/CMS-HIG-19-003_Figure_003-b.png" alt="" width="500">
</div>
<div class="col-lg-6">
<h2>Inclusive search for highly boosted Higgs bosons decaying to bottom quark-antiquark pairs in proton-proton collisions at \(\sqrt{s}=13\) TeV</h2>
<p>A search for standard model Higgs bosons (\(\mathrm{H}\)) produced with transverse momentum (\(p_\mathrm{T}\)) greater than 450 GeV and decaying to bottom quark-antiquark pairs (\(\mathrm{b}\overline{\mathrm{b}}\)) is performed using proton-proton collision data collected by the CMS experiment at the LHC at \(\sqrt{s}= 13\) TeV. The data sample corresponds to an integrated luminosity of 137 fb\(^{-1}\). The search is inclusive in the Higgs boson production mode. Highly Lorentz-boosted Higgs bosons decaying to \(\mathrm{b}\overline{\mathrm{b}}\) are reconstructed as single large-radius jets, and are identified using jet substructure and a dedicated b tagging technique based on a deep neural network.
  For a Higgs boson mass of 125 GeV, an excess of events above the background assuming no Higgs boson production is observed with a local significance of 2.5 standard deviations (\(\sigma\)), while the expectation is 0.7.
  The corresponding signal strength and local significance with respect to the standard model expectation are \( \mu_\mathrm{H} = 3.7 \pm 1.2 (\mathrm{stat}) ^{+0.6}_{-0.7} (\mathrm{syst}) ^{+0.8}_{âˆ’0.5} (\mathrm{theo})\) and \(1.9\,\sigma\).
  Additionally, an unfolded differential cross section as a function of Higgs boson \(p_\mathrm{T}\) for the gluon fusion production mode is presented, assuming the other production modes occur at the expected rates.
</p>
<p>Paper: <a
href="https://arxiv.org/abs/2006.13251">arXiv:2006.13251</a>
<br>Figures: <a href="http://cms-results.web.cern.ch/cms-results/public-results/publications/HIG-19-003/index.html">http://cms-results.web.cern.ch/cms-results/public-results/publications/HIG-19-003</a>
</div>
</div>

<div class="row">
<div class="col-lg-6">
<img class="img-fluid rounded mb-4" src="images/binary_ternary_architecture.png" alt="" width="500">
</div>
<div class="col-lg-6">
<h2>Compressing deep neural networks on FPGAs to binary and ternary precision with \(\texttt{hls4ml}\)</h2>
<p>We present the implementation of binary and ternary neural networks in the \(\texttt{hls4ml}\) library, designed to automatically convert deep neural network models to digital circuits with FPGA firmware.
  We investigate different strategies to reduce networks' resource consumption by reducing the numerical precision of the network parameters to binary or ternary.
  We discuss the trade-off between model accuracy and resource consumption.
  In addition, we show how to balance between latency and accuracy by retaining full precision on a selected subset of network components.
  As examples, we consider two multiclass classification tasks: handwritten digit recognition with the MNIST data set and jet identification with simulated proton-proton collisions at the CERN Large Hadron Collider. The binary and ternary implementation has similar performance to the higher precision implementation while using drastically fewer FPGA resources.
</p>
<p>Paper: <a href="https://doi.org/10.1088/2632-2153/aba042">Mach. Learn.: Sci. Technol. (2020)</a>
<br>Code: <a href="https://github.com/hls-fpga-machine-learning/hls4ml">https://github.com/hls-fpga-machine-learning/hls4ml</a>
</div>
</div>
<div class="row">
<div class="col-lg-6">
<img class="img-fluid rounded mb-4" src="images/bdt_node.png" alt="" width="400">
</div>
<div class="col-lg-6">
<h2>Fast inference of boosted decision trees in FPGAs for particle physics</h2>
<p>We describe the implementation of boosted decision trees in the \(\texttt{hls4ml}\) library, which allows the translation of a trained model into FPGA firmware through an automated conversion process.
  Thanks to its fully on-chip implementation, \(\texttt{hls4ml}\) performs inference of boosted decision tree models with extremely low latency.
  With a typical latency less than 100 ns, this solution is suitable for FPGA-based real-time processing, such as in the Level-1 trigger system of a collider experiment.
</p>
<p>Paper: <a href="https://doi.org/10.1088/1748-0221/15/05/p05026">J. Instrum. 15, P05026 (2020)</a>
<br>Code: <a href="https://github.com/hls-fpga-machine-learning/hls4ml">https://github.com/hls-fpga-machine-learning/hls4ml</a>
</div>
</div>
               <div class="row">
      <div class="col-lg-6">
        <img class="img-fluid rounded mb-4" src="images/flow-Hbb.jpg" alt="" width="500">
      </div>
      <div class="col-lg-6">
        <h2>Interaction networks for the identification of boosted \(H\to b\overline{b}\) decays</h2>
        <p>We develop an algorithm based on an
               interaction network to identify high-momentum
               Higgs bosons decaying to bottom quark-antiquark pairs and
               distinguish them from ordinary jets originating from
               the hadronization of quarks and gluons. Describing the jet shower as a
               combination of particle-to-particle and
               particle-to-vertex interactions, the model is trained
               to learn a jet representation on which the
               classification problem is optimized. The algorithm is
               trained on simulated samples of accurate LHC
               collisions, released by the CMS collaboration on the
               CERN Open Data Portal. The interaction network achieves
               a drastic improvement in the identification performance
	with respect to state-of-the-art algorithms.</p>
	<p>Paper: <a
           href="https://doi.org/10.1103/PhysRevD.102.012010">Phys. Rev. D 102, 012010 (2020)</a>
	<br>Code: <a href="https://github.com/eric-moreno/IN">https://github.com/eric-moreno/IN</a>
      </div>
    </div>
           <div class="row">
      <div class="col-lg-6">
        <img class="img-fluid rounded mb-4" src="images/graph_white.jpg" alt="" width="500">
      </div>
      <div class="col-lg-6">
        <h2>JEDI-net: a jet identification algorithm based on interaction networks</h2>
        <p>We investigate the performance of a jet identification
           algorithm based on interaction networks (JEDI-net) to
           identify all-hadronic decays of high-momentum heavy
           particles produced at the LHC and distinguish them from
           ordinary jets originating from the hadronization of quarks
	and gluons. The jet dynamics are described as a set of
           one-to-one interactions between the jet constituents. Based
           on a representation learned from these interactions, the
           jet is associated to one of the considered categories. The
           presented models give better results with less model
           parameters than other traditional architectures.</p>
	<p>Paper: <a
           href="https://doi.org/10.1140/epjc/s10052-020-7608-4">Eur. Phys. J. C 80, 58 (2020)</a>
	<br>Code: <a href="https://github.com/jmduarte/JEDInet-code">https://github.com/jmduarte/JEDInet-code</a>
      </div>
    </div>
        <div class="row">
      <div class="col-lg-6">
        <img class="img-fluid rounded mb-4" src="images/sonic.jpg" alt="" width="500">
      </div>
      <div class="col-lg-6">
        <h2>FPGA-accelerated machine learning inference as a service for particle physics computing</h2>
        <p>We demonstrate that the acceleration of machine learning
        inference as a service represents a nondisruptive, heterogeneous
        computing solution for particle physics experiments. We retrain the ResNet-50
        convolutional neural network to achieve state-of-the-art
        performance for top quark jet tagging at the LHC and apply a
        ResNet-50 model with transfer learning for neutrino event
        classification. Using Project Brainwave by Microsoft to
        accelerate the ResNet-50 image classification model, we
        achieve average inference times of 60 (10) milliseconds with
        our experimental physics software framework using Brainwave as
        a cloud (edge or on-premises) service, and a maximum throughput of 600-700 inferences per second.</p>
	<p>Paper: <a href="https://doi.org/10.1007/s41781-019-0027-2">Comput. Softw. Big. Sci. 3, 13 (2019)</a>
	<br>Code: <a href="https://github.com/hls-fpga-machine-learning/SonicCMS">https://github.com/hls-fpga-machine-learning/SonicCMS</a>
      </div>
    </div>
    <!-- /.row -->
    <div class="row">
      <div class="col-lg-6">
        <img class="img-fluid rounded mb-4" src="images/flow-hls4ml.jpg" alt="" width="500">
      </div>
      <div class="col-lg-6">
        <h2>Fast inference of deep neural networks in FPGAs for particle physics</h2>
        <p>We develop a package based on high-level Synthesis (HLS) called \(\texttt{hls4ml}\) to build machine
    learning models in FPGAs for extremely low-latency applications
    (less than one microsecond). The use of HLS increases accessibility
    across a broad user community and allows for a drastic decrease in
    firmware development time. We map out FPGA resource usage and
    latency versus neural network hyperparameters to identify the
    problems in particle physics that would benefit from performing
    neural network inference with FPGAs. For a case study jet
    substructure model, we fit well within the available resources of
	modern FPGAs with a latency on the scale of 100 ns.</p>
	<p>Paper: <a href="https://doi.org/10.1088/1748-0221/13/07/P07027">J. Instrum. 13, P07027 (2018)</a>
	<br>Code: <a href="https://github.com/hls-fpga-machine-learning/hls4ml">https://github.com/hls-fpga-machine-learning/hls4ml</a>
      </div>
    </div>
    <!-- /.row -->

  </div>
  <!-- /.container -->

  <!-- Footer -->
  <footer class="py-5 bg-dark">
    <div class="container">
      <p class="m-0 text-center text-white">Copyright &copy; Javier Duarte 2020</p>
    </div>
    <!-- /.container -->
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

</body>

</html>
